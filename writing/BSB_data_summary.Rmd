---
title: "Black Sea Bass Data Summary"
author: "Min-Yang Lee"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  html_document:
    df_print: paged
    fig_caption: yes
  pdf_document:
    keep_tex: yes
    fig_caption: yes
    number_sections: yes
header-includes: \usepackage{setspace}\doublespacing
urlcolor: blue
editor_options:
  chunk_output_type: console
fontsize: 12pt
---

# Summary and Housekeeping

This is a data summary document. I ran the files ``\stata_code\data_extraction_processing\extraction\commercial\00_cams_extraction.do`` and ``00_extraction_wrapper.do``

I also ran all the files in ``\stata_code\data_extraction_processing\analysis`` to do some exploratory analysis. 

Warnings: There is something funky going on with VA "status=PZERO" starting in 2021.  There is also something funky going on with Delaware landings, but there are no hullids/permit numbers so I don't think this will throw anything off at the vessel level.


\clearpage


 <!---- 
 The global_options chunk loads libraries, sets options, figures out if you're on a desktop or server, sets years, and sets graphing options
 --->
```{r global_options, include=FALSE}

 library("foreign")
 library("here")
 library("tidyverse")
 library("scales")
 library("knitr")
 library("lubridate")
 library("kableExtra")
 library("haven")
 library("mapview")
 library("sf")
 library("viridis")
here::i_am("writing/BSB_data_summary.Rmd")

#############################################################################
#knitr options

knitr::opts_chunk$set(echo=FALSE, warning = FALSE, error = FALSE, message = FALSE, comment = FALSE, cache = FALSE, progress = TRUE, verbose = FALSE, 
											dpi = 600)
options(tinytex.verbose = TRUE)
# options(knitr.table.format = "latex")
options(scipen=999)

lbs_per_mt<-2204.62
#############################################################################
my_images<-here("images")

descriptive_images<-here("images","descriptive")
exploratory_images<-here("images","exploratory")


# Read in statistical areas
stat_areas_location<-here("data_folder","external","shapefiles","Statistical_Areas_2010.shp")
stat_areas <- st_read(dsn = stat_areas_location)

#trim out some stat areas that I don't care about.
stat_areas<-stat_areas %>%
  dplyr::filter(Id>=460) %>% # Canada
   dplyr::filter(Id<=711) %>% # SERO
  dplyr::filter(!Id %in% c(640,650,660,670,680) ) #Offshore

# mapview(stat_areas)

```




```{r main_overview, fig.show = "hold", out.width = "48%", fig.cap="VTR-Observer modeled heat map of black sea bass, summer flounder, scup, and loligo squid",  fig.align = "center", echo=FALSE}
knitr::include_graphics(here("data_folder","external","web_maps",c("SPP_335_QTYKEPT.gif","SPP_121_QTYKEPT.gif","SPP_329_QTYKEPT.gif","SPP_801_QTYKEPT.gif")))
```


# Regulations and Background

<!--- Include the next 2 child documents.   --->
```{r, child=here("writing", c("BSB_history.Rmd", "BSB_economic_background.Rmd")),  eval=TRUE}
```

# Related 

```{r, child=here("writing", c("BSB_Related.Rmd")),  eval=TRUE}
```

# Research Questions

1.  Can we use information in prices to assign a market category to the unclassified fish?  

    * Run a categorical model (ordered or un-ordered logit?) with price as a right hand side variable.  Then predict out of sample for the unclassified market category.
    
    * Estimate a latent class (finite mixture model) on the price of unclassified, where there are a moderate number of classes (say small and large).  A test of the model would be to see how well it does on the classes.
  
    * There's approximately 5% of fish that are Unclassified, so the magnitude of the effect on the stock assessment enterprise is probably minimal. But it might illustrate areas where we can shift sampling. 
  
2. Three states have implemented a catch share for Black Sea Bass. What has happened in these fisheries?

    * Triple diff: pre-post/ treat-control, plus the gear treatments might vary?
      * Prices -- probably not possible, SUTVA unlikely since they all produce BSB.
      * Season length is more likely, but what does this mean when some states are managed by bi-weekly in-season adjustments?
    * The Three catch share states have very similar regulations: IFQ, minimum mesh/vent, and minimum size.
    * The other states seem to also have similar regulations: Limited access, mesh/vent, minimum sizes, and day/week possession limits.
      * What do we "need" to say anything interesting?  We have 1996-2002 as "pre" data.
      * How do I "add" things to a choice set?  
          * Is it enough to 'flag' 
    * The quota markets are thin -- it looks like 6-30 permits/people. Does this mean we have to model quota usage in a dynamic setting?
  
3. All of the states have limited access black sea bass. These limits make it hard for vessels from other states to land.  What are the welfare effects? Is this a good idea? What is the political economy?  What is the economic game and strategic interactions at the ASFMC and what are the objectives of the individuals?
    
    * Talk to Emily K (Although Emily is moving off BSB) at GARFO.  MAFMC and ASMFC staff too?
    * What kind of information exists at the state level? Can we get any more info, especially from MA, RI, and CT about fishing effort?
    * How has the BSB fishery played out for the catch share states compared to the non-catch share states? Greg has been using the cost data together to put together profitability profiles. 
        * For firms without a federal permit, I don't know how to feel about that.
    * Entangled in this might be a model of landing locations for firms. Do we try to look back to the 'pre state allocation' decisions?  This would be around 1999-2002. The aggregate quotas went in March 31, 2023.   
    * Have the possession limits concentrated fishing effort in the nearshore (summer) months? Is this good or bad?  Are offshore northern waters basically inaccessible?
    

# Things to Figure out

1. Has commercial quota ever been transferred?

1. When did each of the states do limited entry for black sea bass?  Importantly, when did they do 'landing permits' or restrictions?

1. Did trip length shift in 2003. Did fish start traveling less (after catch)? 

    * With just a landing restriction, I'd expect firms to travel less. But the elimination of quarterly TACs muddles things a bit.

1. Data issues with DE. And With VA.

1. Can you discard legal-sized fish?

1. Do dealers coordinate among themselves or with vessels to control the pace of landings within a year.

1. Endogenous treatment of the catch share?

1. How joint is the catch of the four stocks?

1. Use it or lose-it at the state level? I don't think so.

1. How much does it cost to get a state permit?
  * Varies by state.
  * Commercial permits for Residents are usually in the 100-300 per year range. This might cover all species or endorsements might be required at an additional fee in the 20-100 per year range.
  * Commercial permits for non-residents are usually 300-500 per year, endorsements again extra.
  * Transferring in a state LA permit will be tricky. 

1. Add the state level allocation info.

# Data




CAMS is the primary data source. CAMS is a joining of Dealer to other data sources, including VTR. 

I've always thought of the dealer data as a record of "transactions" -- each row represents a sale from a vessel to a dealer of a market category of fish (PERMIT-DEALER-DATE-NESPP4). There might be instances where there are multiple of these records per day (say a vessel lands 2x in a day), but these should not be too common. "trip level" information can be brought in through the VTR serial number, but sometimes this is not enough. From a stock assessment perspective, if a vessel fishes in two statistical areas, that information may be needed and the landings might need to be allocated to a statistical area.  Even if sales were at the (PERMIT-DEALER-DATE-statistical area-NESPP4) level, which they are not, we wouldn't be able to get this information because only 1 VTR per trip is observed per "trip."

A row in CAMS_LAND is an "allocated" landing; it is not necessarily a sales transaction (PERMIT-DEALER-DATE-NESPP4).



CAMS matches dealer records to VTR records. For trip-level things, I'm willing to accept 2 CAMS status as good -- "MATCH" and "DLR_ORPHAN_SPECIES." 

MATCH = records fully match at the CAMSID-ITIS_GROUP1 level; 

DLR_ORPHAN_SPECIES = in dealer. Trip is in vtr, but the *species* is not in VTR

DLR_ORPHAN_TRIP = in dealer. Neither Trip nor species is in vtr 

VTR_ORPHAN_SPECIES = trip is in dealer, but species in not in dealer. trip and species are in VTR

VTR_ORPHAN_TRIP = neither trip nor species are in dealer. trip and species are in VTR.

VTR_NOT_SOLD = VTR records kept for bait-home-consumption and therefore not sold to the dealer and not in dealer

PZERO = Records where PERMIT = '000000'. These are not included in the apportionment or imputation processes. The CAMS matching algorithm requires a permit number.  Some of these possibly could be matched through the algorithm, because there sometimes is a hullnum.  But i spot checked some and it didnt' work well

CFDERS_ALL_YEARS has a CF_License (Commercial fisherman license issued by a State)  and a state_dnum (State Dealer License Number) field. These are interesting. Do I "need" anything? or can I make do with these as dummies?


```{r data_summary, eval=TRUE}
vintage_string<-list.files(here("data_folder","raw","commercial"), pattern=glob2rx("landings_all*.dta"))
vintage_string<-gsub("landings_all_","",vintage_string)
vintage_string<-gsub(".dta","",vintage_string)
vintage_string<-max(vintage_string)
all_landings<-haven::read_dta(here("data_folder","raw","commercial", paste0("landings_all_",vintage_string,".dta")))
# nrows(all_landings)
# summary(all_landings)

working_landings<-all_landings %>%
  dplyr::filter(merge_species_codes==3) %>%
  dplyr::filter(!(permit %in% c(190998,290998,390998,490998))) %>%
  dplyr::filter(!(hullid=="0000000" & permit==0)) %>%
  dplyr::filter(!(hullid=="000000" & permit==0)) %>%
  dplyr::filter(!hullid=="FROM_SHORE") %>%
  dplyr::filter(state %in% c("CT","DE", "MA","MD", "NC","NJ", "NY","RI","VA")) %>%
  mutate(dlr_date=lubridate::date(dlr_date))


row_count<-nrow(working_landings)

total<-working_landings%>%
  summarise(year=9999,
            all=n(),
            all_lbs=sum(lndlb/1000),
            all_trips=n_distinct(camsid))

obs_by_year<-working_landings%>%
  group_by(year)  %>%
  summarise(all=n(),
            all_lbs=sum(lndlb/1000),
            all_trips=n_distinct(camsid))# %>%
#  bind_rows(total)


#kbl(obs_by_year, digits=0,booktabs=T, align=c("l",rep("r", times=2)), caption =  "CAMS observations, thousands of pounds, and unique trips (camsids)year") %>%
#    kable_styling(full_width = T,latex_options = "hold_position") %>% 
#     row_spec(0,bold=FALSE)
```

Most of the locations without a match are status=PZERO. I think it's reasonable to deduce that those trips are in state waters, within 3 nautical miles of land.  The good location column is just a quick check that lon is not na. 
```{r matchOS, eval=TRUE}


matching1<-working_landings%>%
  ungroup() %>%
  mutate(good_location=!is.na(lon_dd)) %>%
  group_by(status,good_location)%>%
  summarise(land=sum(lndlb, na.rm=TRUE))



matching<-working_landings%>%
  ungroup() %>%
  mutate(MATCH_OS=case_when(
            status=="MATCH" ~ "MATCH_OS",
            status=="DLR_OPRHAN_SPECIES" ~ "MATCH_OS",
            .default="NOT"),
         good_location=!is.na(lon_dd)) %>%
  group_by(MATCH_OS,good_location)%>%
  summarise(land_mt=sum(lndlb/lbs_per_mt, na.rm=TRUE))


kbl(matching, digits=1,booktabs=T, align=c("l",rep('r',times=2)), caption =  "Good locations, all years combined") %>%
    #column_spec(5:8, width = "2cm")
    kable_styling(full_width = F) %>% 
      row_spec(0,bold=FALSE) 

```














This figure shows all landings of bsb and all "trips" that landed bsb in CAMS.

```{r all_trips_and_landings, eval=TRUE, fig.cap = paste("All landings and total trips")}


# Value used to transform the data
coeff <- 1
PoundsColor <- rgb(0.2, 0.6, 0.9, 1)
TripColor <- "#69b3a2"

ggplot(obs_by_year, aes(x=year)) +
  
  geom_line( aes(y=all_lbs), color=PoundsColor, linewidth=2) + 
  geom_line( aes(y=all_trips / coeff),color=TripColor, linewidth=2) + # Divide by 10 to get the same range than the temperature
  
  scale_y_continuous(
    
    # Features of the first axis
    name = "Commerical Pounds",
    
    # Add a second axis and specify its features
    sec.axis = sec_axis(~.*coeff, name="Trips")
  ) +
  theme(
    axis.title.y = element_text(color = PoundsColor, size=13),
    axis.title.y.right = element_text(color = TripColor, size=13)
  )







```




```{r data_summary_trips, eval=TRUE}
# how many unique trips and how many with a good matching status?
# I'm assuming that 


total<-working_landings%>%
  dplyr::filter(status %in% c("MATCH","DLR_ORPHAN_SPECIES")) %>%
  summarise(year=9999,
            match=n(),
            match_lbs=sum(lndlb/1000),
            match_trips=n_distinct(camsid)) 

obs_match<-working_landings%>%
  dplyr::filter(status %in% c("MATCH","DLR_ORPHAN_SPECIES")) %>%
  group_by(year) %>%
  summarise(match=n(),
            match_lbs=sum(lndlb/1000),
            match_trips=n_distinct(camsid)) #%>%
#  bind_rows(total)
```

This figure shows just landings of bsb and "trip" where we have a good match between dealer and VTR.

```{r matched_trips_and_landings, eval=TRUE, fig.cap = paste("cams matched landings and total trips")}
# Value used to transform the data
coeff <- 1
PoundsColor <- rgb(0.2, 0.6, 0.9, 1)
TripColor <- "#69b3a2"

ggplot(obs_match, aes(x=year)) +
  
  geom_line( aes(y=match_lbs), color=PoundsColor, linewidth=2) + 
  geom_line( aes(y=match_trips / coeff),color=TripColor, linewidth=2) + # Divide by 10 to get the same range than the temperature
  
  scale_y_continuous(
    
    # Features of the first axis
    name = "Commerical Pounds",
    
    # Add a second axis and specify its features
    sec.axis = sec_axis(~.*coeff, name="Trips")
  ) +
  theme(
    axis.title.y = element_text(color = PoundsColor, size=13),
    axis.title.y.right = element_text(color = TripColor, size=13)
  ) 



```

```{r data_summary_trips_table, eval=FALSE}

kbl(obs_match, digits=0,booktabs=T, align=c("l",rep("r", times=2)), fig.cap =   "CAMS observations, thousands of pounds, and unique trips (camsids)year") %>%
    kable_styling(full_width = T,latex_options = "hold_position") %>% 
      row_spec(0,bold=FALSE) 

```

This is a quick and dirty summary of trips. I group by CAMSID, permit, hullid, and year. The grouping by CAMSID, permit, and hullid is inocuous. 

the na.rm=TRUE option for the value sum is not inocuous.  There are some rows with value=null. We either need to fill in a price or remove the entire row.  Relatedly, there are some rows with value=0.  We might want to do the same.  Both of these might legitimately arise from home consumption or from "unsold".  There's also some suspiciousness regarding state level aggregates, but those are probably trimmed out already. 

I pull through the first gear and area for each camsid. I sum up the landed pounds and value. 

```{r trip_level_info, eval=TRUE}

trip<-working_landings %>%
  dplyr::filter(status %in% c("MATCH","DLR_ORPHAN_SPECIES")) %>%
  group_by(camsid, year, permit, hullid) %>%
  summarise(lndlb=sum(lndlb, na.rm=TRUE),
            value=sum(value, na.rm=TRUE),
            negear=first(negear),
            area=first(area))

# Trip level summary statistics , by year
summ1<-trip %>%
  group_by(year) %>%
  summarise(count=n(),
    avg_lndlb=mean(lndlb),
            p10_lndlb = quantile(lndlb, probs = .10),

          p25_lndlb = quantile(lndlb, probs = .25),

              p50_lndlb = quantile(lndlb, probs = .50),
            p60_lndlb = quantile(lndlb, probs = .60),
            p75_lndlb = quantile(lndlb, probs = .75),
            p90_lndlb = quantile(lndlb, probs = .90),
            p95_lndlb = quantile(lndlb, probs = .95),
            p99_lndlb = quantile(lndlb, probs = .99)
        )
```

      
```{r trip_level_table, eval=FALSE}

kbl(summ1, digits=0,booktabs=T, align=c("l",rep("r",ncol(summ1)-1)), caption =  "Trips, average landings, and percentiles of the distribution") %>%
    kable_styling(full_width = T,latex_options = "hold_position") %>% 
      row_spec(0,bold=FALSE) 

```

```{r trip_level_graphs_pounds, eval=TRUE, fig.cap = paste("Trip level pounds and the 25th and 90th percentiles.I wonder what is driving the secular trend in increases in pounds per trip from about 2008 to present.")}

ggplot(summ1)+
aes(x=year, y=avg_lndlb, ymin=p25_lndlb, ymax=p90_lndlb) +
  geom_line() + 
   geom_ribbon(alpha=0.5)+
  ylab("Pounds per trip")
```

```{r trips_bsb, eval=FALSE, fig.cap = paste("Trips with black sea bass")}
ggplot(summ1)+
aes(x=year, y=count) +
  geom_line(color="grey",size=2) +
  ylab("Trips")
```



## by state
The number of observations is a little too high, because a vessel could bring fish caught on a single trip to multiple states. But this probably doesn't happen too much. 

```{r state_trip, eval=TRUE}

trip2<-working_landings %>%
  dplyr::filter(status %in% c("MATCH","DLR_ORPHAN_SPECIES")) %>%
  group_by(camsid, year, permit, hullid, state) %>%
  summarise(lndlb=sum(lndlb, na.rm=TRUE),
            value=sum(value, na.rm=TRUE),
            negear=first(negear),
            area=first(area))





# Trip level summary statistics , by year
summ2<-trip2 %>%
  group_by(state, year) %>%
  summarise(count=n(),
    avg_lndlb=mean(lndlb),
          p25_lndlb = quantile(lndlb, probs = .25),
            p50_lndlb = quantile(lndlb, probs = .50),
            p60_lndlb = quantile(lndlb, probs = .60),
            p75_lndlb = quantile(lndlb, probs = .75),
            p90_lndlb = quantile(lndlb, probs = .90),
            p95_lndlb = quantile(lndlb, probs = .95),
            p99_lndlb = quantile(lndlb, probs = .99)
        )
```

```{r state_trip_table2, eval=FALSE}

kbl(summ2 %>%
      dplyr::filter(state %in% c("MA","RI","CT"))
    
    
    , digits=0,booktabs=T, align=c("l",rep("r",ncol(summ2)-1)), caption =  "Trips, average landings, and percentiles of the distribution, grouped by state") %>%
    kable_styling(full_width = T,latex_options = "hold_position") %>% 
      row_spec(0,bold=FALSE) 


```


```{r state_landings, eval=TRUE, fig.cap=paste("Average landings, with 25th and 90th percentiles. ")}

ggplot(summ2)+
aes(x=year, y=avg_lndlb, ymin=p25_lndlb, ymax=p90_lndlb) +
  geom_line() + 
   geom_ribbon(alpha=0.5)+
  ylab("Pounds per trip")+
    facet_wrap(~state)


```


```{r state_trips, eval=TRUE,fig.cap=paste("Trips by year. I let the scale vary across the state")}
ggplot(summ2)+
aes(x=year, y=count) +
  geom_line(color="grey",linewidth=2) +
  ylab("Trips")+ 
    facet_wrap(~state, scale="free_y")

```




```{r state_trips_fixy, eval=TRUE,fig.cap=paste("Trips by year. I fixed the yscale to be constant across the states.")}
ggplot(summ2)+
aes(x=year, y=count) +
  geom_line(color="grey",linewidth=2) +
  ylab("Trips")+ 
    facet_wrap(~state)

```





```{r state_trip2, eval=FALSE}


      
kbl(summ2 %>%
      dplyr::filter(state %in% c("NY","NJ", "DE"))
    
    
    , digits=0,booktabs=T, align=c("l",rep("r",ncol(summ2)-1)), caption =  "Trips, average landings, and percentiles of the distribution, grouped by state") %>%
    kable_styling(full_width = T,latex_options = "hold_position") %>% 
      row_spec(0,bold=FALSE) 


```





```{r state_trip3, eval=FALSE}

kbl(summ2 %>%
      dplyr::filter(state %in% c("MD", "VA", "NC"))
    
    
    , digits=0,booktabs=T, align=c("l",rep("r",ncol(summ2)-1)), caption =  "Trips, average landings, and percentiles of the distribution, grouped by state") %>%
    kable_styling(full_width = T,latex_options = "hold_position") %>% 
      row_spec(0,bold=FALSE) 


```





```{r trip_length, eval=TRUE}


trip_length<-working_landings %>%
  dplyr::filter(status %in% c("MATCH","DLR_ORPHAN_SPECIES"))%>%
  dplyr::filter(!is.na(record_sail)) %>%
  dplyr::filter(!is.na(record_land)) %>%
  mutate(trip_hours=int_length(interval(record_sail, record_land))/(3600) )

  
  tl_table<-trip_length %>%
  group_by(year)%>%
  summarise(count=n(),
          avg_trip_hours=mean(trip_hours),
          p10_trip_hours = quantile(trip_hours, probs = .10),
          p25_trip_hours = quantile(trip_hours, probs = .25),
          p50_trip_hours = quantile(trip_hours, probs = .50),
            p75_trip_hours = quantile(trip_hours, probs = .75),
            p90_trip_hours = quantile(trip_hours, probs = .90),
            p95_trip_hours = quantile(trip_hours, probs = .95),
            p99_trip_hours = quantile(trip_hours, probs = .99)
  )
```
      
      
 
```{r trip_length_graphs, eval=TRUE}

ggplot(tl_table)+
aes(x=year, y=avg_trip_hours, ymin=p25_trip_hours, ymax=p90_trip_hours) +
  geom_line() + 
   geom_ribbon(alpha=0.5)+
  ylab("Trip length (hours)")


```
 
      
```{r trip_length_table, eval=FALSE}
kbl(tl_table , digits=0,booktabs=T, align=c("l",rep("r",ncol(tl_table)-1)), caption =  "Trips, average length (hours), and percentiles of the distribution") %>%
    kable_styling(full_width = T,latex_options = "hold_position") %>% 
      row_spec(0,bold=FALSE) 
```

At least on the Trip length metric, NC is different. They're taking 5 day trips instead of half day trips like in MD.  

New York also shifted to 1/2 day trips in 2009. I suspect a possession limit change did this.  Possession limits make it difficult to go far offshore and shift effort inshore.  But it looks like the 'menu' of trips/possesions have had an effect later in the time series in NY.

I'm a little suspicious of the DE 90th percentile in recent years.


```{r state_trip_length, eval=TRUE}
 tl_table2<-trip_length %>%
  group_by(state, year)%>%
  summarise(count=n(),
          avg_trip_hours=mean(trip_hours),
          p10_trip_hours = quantile(trip_hours, probs = .10),
          p25_trip_hours = quantile(trip_hours, probs = .25),
          p50_trip_hours = quantile(trip_hours, probs = .50),
            p75_trip_hours = quantile(trip_hours, probs = .75),
            p90_trip_hours = quantile(trip_hours, probs = .90),
            p95_trip_hours = quantile(trip_hours, probs = .95),
            p99_trip_hours = quantile(trip_hours, probs = .99)
  )
```
```{r state_trip_length_table, eval=FALSE}

kbl(tl_table2 , digits=0,booktabs=T, align=c("l",rep("r",ncol(tl_table2)-1)), caption =  "Trips, average length (hours), and percentiles of the distribution, grouped by state") %>%
    kable_styling(full_width = T,latex_options = "hold_position") %>% 
      row_spec(0,bold=FALSE) 

```

```{r state_trip_lengthgraph, eval=TRUE, fig.cap=paste("Average Trip length by state, with 25th and 90th percentiles. The different kinds of fleets is interesting to see here. For a couple states (CT, RI, and MA), we don't have a great match rate, likely because of trips by state-only vessels. The state-only vessels are likely to be taking very short trips.")}

ggplot(tl_table2)+
aes(x=year, y=avg_trip_hours, ymin=p25_trip_hours, ymax=p90_trip_hours) +
  geom_line() + 
   geom_ribbon(alpha=0.5)+
  ylab("Pounds per trip")+
    facet_wrap(~state)


```




## Total landings by statistical area

```{r statistical_areas, eval=TRUE}
stat_area_summary<-working_landings %>%
  dplyr::filter(status %in% c("MATCH","DLR_ORPHAN_SPECIES"))%>%
  dplyr::filter(area>=500) %>% # In US
  dplyr::filter(area<=711) %>%
  group_by(area) %>%
  summarize(landings=sum(lndlb/1000)) %>%
  ungroup()%>%
  mutate(total=sum(landings))%>%
  mutate(pct=landings/total)%>%
  select(-total)

stat_area_recent<-working_landings %>%
  dplyr::filter(status %in% c("MATCH","DLR_ORPHAN_SPECIES"))%>%
  dplyr::filter(area>=500) %>% # In US
  dplyr::filter(area<=711) %>%
  dplyr::filter(year>=2019)%>%
  group_by(area) %>%
  summarize(landings2018_2023=sum(lndlb/1000)) 


stat_area_summary<-stat_area_summary %>%
  left_join(stat_area_recent, by=join_by(area==area))


# just show the stat areas greater than 1.5%
kbl(stat_area_summary  %>%
  dplyr::filter(pct>=0.015) %>%
  arrange(-landings) %>%
  select(-pct)
  
  , format.args = list(big.mark = ","), digits=0,booktabs=T, align=c("l",rep("r",ncol(stat_area_summary)-1)), caption =  "Landings (thousands of pounds) over the full time series and recent 5 years, by statistical area") %>%
kable_styling(full_width = T,latex_options = "hold_position") %>% 
      row_spec(0,bold=FALSE) 

```


```{r map_stat_areas, eval=TRUE}
stat_areas<-stat_areas %>%
  left_join(stat_area_summary, by=join_by(Id==area))

#mapview(stat_areas, zcol="pct",at = seq(0.025, .25, 0.025))
```



```{r stat_area_500syearly, eval=TRUE, fig.cap=paste("annual matched landings from the 500s, areas with minimal landings excluded")}

stat_area_yearly<-working_landings %>%
  dplyr::filter(status %in% c("MATCH","DLR_ORPHAN_SPECIES"))%>%
  dplyr::filter(area>=500) %>% # In US
  dplyr::filter(area<=711) %>%
  group_by(area, year) %>%
  summarize(landings=sum(lndlb/1000))%>%
  ungroup()%>%
  arrange(area, year)


balanced.panel <- stat_area_yearly %>%  
  complete(nesting(area), year = full_seq(year, period = 1))

balanced.panel<-balanced.panel %>%
    dplyr::filter(!area %in%c(511,512,513,543,542,561,515,534,562)) 

ggplot(balanced.panel %>% dplyr::filter(area<600))+
  geom_line() + 
  aes(x=year, y=landings) +
    ylab("Landed Pounds (000s)")+ 
    facet_wrap(~area)



```
```{r stat_area_500syearlyFree, eval=TRUE, fig.cap=paste("annual matched landings from the 500s, areas with minimal landings excluded, Yscale free")}


ggplot(balanced.panel %>% dplyr::filter(area<600))+
  geom_line() + 
  aes(x=year, y=landings) +
    ylab("Landed Pounds (000s)")+ 
    facet_wrap(~area, scale="free_y")



```



```{r stat_area_600syearly, eval=TRUE, fig.cap=paste("annual matched landings from the 600s, areas with minimal landings excluded")}
balanced.panel<-balanced.panel %>%
    dplyr::filter(!area %in%c(624,627,629,633,634,635,637,638,639,640,650)) 


ggplot(balanced.panel %>% dplyr::filter(area>=600 & area<700))+
  geom_line() + 
  aes(x=year, y=landings) +
    ylab("Landed Pounds (000s)")+ 
    facet_wrap(~area)

```

```{r stat_area_600syearlyFree, eval=TRUE, fig.cap=paste("annual matched landings from the 600s, areas with minimal landings excluded. Yscale free")}
balanced.panel<-balanced.panel %>%
    dplyr::filter(!area %in%c(624,627,629,633,634,635,637,638,639,640,650)) 


ggplot(balanced.panel %>% dplyr::filter(area>=600 & area<700))+
  geom_line() + 
  aes(x=year, y=landings) +
    ylab("Landed Pounds (000s)")+ 
    facet_wrap(~area, scale="free_y")

```





## State level landings by area

```{r statistical_areas_states, eval=TRUE}
stat_area_state_summary<-working_landings %>%
  dplyr::filter(status %in% c("MATCH","DLR_ORPHAN_SPECIES"))%>%
  dplyr::filter(area>=500) %>% # In US
  dplyr::filter(area<=711) %>%
  group_by(state,area) %>%
  summarize(landings=sum(lndlb/1000)) %>%
  group_by(state) %>%
  mutate(total=sum(landings))%>%
  mutate(pct=landings/total)%>%
  select(-total) %>%
    arrange(state, -landings)

# Rebin anything less than 2.5% to the 999 area
state_area_all_others <-stat_area_state_summary %>%
  mutate(area=ifelse(pct<=.025, 999,area))%>% 
  group_by(state,area) %>%
  summarize(landings=sum(landings/1000)) %>%
  group_by(state) %>%
  mutate(total=sum(landings))%>%
  mutate(pct=landings/total)%>%
  select(-total) %>%
    arrange(state, -landings)



ggplot(state_area_all_others %>%mutate(area=as.factor(area))
       , aes(fill=area, y=landings, x=state)) + 
    geom_bar(position="stack", stat="identity")  + 
    scale_fill_viridis(discrete=TRUE)



```



```{r stat_areas, fig.show = "hold", out.width = "75%", fig.cap="GARFO statistical Areas",  fig.align = "center", echo=FALSE}
knitr::include_graphics(here("data_folder","external","shapefiles","statisticalareas.jpg"))
```


```{r pies, eval=TRUE}

state_area_all_others<-state_area_all_others %>%
   mutate(area=as.factor(area)) %>%
group_by(state) %>%
  arrange(desc(area)) %>%
  mutate(prop = landings / sum(landings) *100) %>%
  mutate(ypos = cumsum(prop)- 0.5*prop ) %>%
  ungroup()


ggplot(state_area_all_others, aes(x="", y=prop, fill=area)) +
  facet_wrap(~state) +
  geom_bar(stat="identity", width=1) +
  coord_polar("y", start=0) + 
  theme_void() + 
  theme(legend.position="none") +
  geom_text(aes(y = ypos, label = area), color = "white", size=3) + 
  scale_fill_viridis(discrete=TRUE)

```


```{r sql_spot_checks, eval=FALSE}

select hullnum, vtrserno, year, year_link, port, dealnum, vessel_name, permit, nespp3, nespp4, spplndlb, sppvalue, cf_license, dersource, partner_code, partner_affiliation, state_dnum, dealer_rpt_id, landing_seq, cfders_id 
from nefsc_garfo.cfders_all_years where permit='000000' and vtrserno is not null and year>=2015;


select * from nefsc_garfo.trip_reports_document where docid in (

select docid from nefsc_garfo.trip_reports_images where serial_num in ('215022331', '215000352','445789'));
```

## Port switches

The following bar chart is the frequency count of permits that switch ports within a year. A switch is defined when sequential BSB trips did not land in the same port. This is top-coded at 5 switches.




```{r port_switches_over_time, eval=TRUE}

pounds<-working_landings %>%
  dplyr::filter(status %in% c("MATCH","DLR_ORPHAN_SPECIES")) %>%
  group_by(camsid) %>%
  summarise_at(c("lndlb", "value"), sum, na.rm = TRUE)


attrib<-working_landings %>%
  dplyr::filter(status %in% c("MATCH","DLR_ORPHAN_SPECIES")) %>%
  group_by(camsid, permit, hullid) %>%
  summarise_at(c("state","port", "state", "dlr_date"), first) %>%
  left_join(pounds, by=join_by(camsid==camsid)) %>%
  group_by(permit, camsid)%>%
  arrange(permit, dlr_date) %>%
  mutate(statecd=floor(port/10000),
         countycd=port %% 100) %>%
  mutate(port2=(port %%10000-countycd)/100)
  

attrib<-attrib %>%
  group_by(permit)%>%
  mutate(port_diff = port - dplyr::lag(port))%>%
  mutate(changed_port=ifelse(port_diff %in% c('0'),0,1))%>%
   mutate(changed_port=ifelse(is.na(port_diff),NA,changed_port))

port_switchers_yr <-attrib %>%
  mutate(year=lubridate::year(dlr_date))%>%
  group_by(permit, year) %>%
  summarise(changed_port=sum(changed_port, na.rm=TRUE))%>%
  mutate(changed_port=ifelse(changed_port>=5,5,changed_port))%>%
  group_by(year, changed_port) %>%
  summarise(count=n())%>%
  mutate(changed_port=factor(changed_port, level=5:0)) %>%
  ungroup()


ggplot(port_switchers_yr
       , aes(fill=changed_port, y=count, x=year)) + 
    geom_bar(position="stack", stat="identity") + 
  scale_fill_viridis(discrete=TRUE) 


```

## State switches

The following bar chart is the frequency count of permits that switch states within a year. A switch is defined when sequential BSB trips did not land in the same state. This is top-coded at 5 switches.


```{r state_switches, eval=TRUE}
state_switchers<-attrib %>%
  group_by(permit)%>%
  mutate(state_diff = statecd - dplyr::lag(statecd,1))%>%
  mutate(changed_state=ifelse(state_diff %in% c('0'),0,1))%>%
   mutate(changed_state=ifelse(is.na(state_diff),NA,changed_state))

state_switchers2<-state_switchers %>%
#  group_by(permit)%>%
  dplyr::filter(changed_state == 1 | dplyr::lead(changed_state,1)==1) 



state_switchers_yr <-state_switchers %>%
  mutate(year=lubridate::year(dlr_date))%>%
  group_by(permit, year) %>%
  summarise(changed_state=sum(changed_state, na.rm=TRUE))%>%
  mutate(changed_state=ifelse(changed_state>=5,5,changed_state))%>%
  group_by(year, changed_state) %>%
  summarise(count=n())%>%
  mutate(changed_state=factor(changed_state, level=5:0)) %>%
  ungroup()


ggplot(state_switchers_yr
       , aes(fill=changed_state, y=count, x=year)) + 
    geom_bar(position="stack", stat="identity")  + 
  scale_fill_viridis(discrete=TRUE) 

```

## Movement over time

One descriptive thing is to look at the locations fished by state. A quick and dirty way is just to landings-weight the VTR points. and compute a center of mass based on that. A slightly more accurate would be to do some sort of contour plot.





## State level matching

I feel pretty confident about being able to model the behavior of all BSB participants in DE, MD, NJ, and VA. This is 3 catch-share fisheries and 1 regulated limited-access fishery.  NC is a little uncertain.  If we can get something out of the state-level reports -- they might have dates or total trips at the vessel level?  We know that the non VTR trips would have had to be in state waters.

I feel pretty confident about being able to model the behavior of *federally* permitted fishing vessels.  However, in NY, RI, CT, and MA a very large fraction of the landings are not matchable to VTRs.  If we need to say something about the NY, RI, CT, and MA fishery based on the federally permitted vessels, we might be able to pull some statistics based on Coast Guard vessel data (https://www.fisheries.noaa.gov/foss/f?p=215:4:8375418615201:::::) and make some sort of claim based on length, hp, age, or tonnage.  Matching everything is hopeless. And there are still some hullid's that do not show up in this database, I think because the "hullid" is actually a state identifier that does not show up in the coast guard db. 

The proportion of good matches landings in Delaware, Maryland, New Jersey, and Virginia are very high.  Matches for North Carolina are moderate, I wouldn't be surprised if this is a boundary issue with the south Atlantic.  New York, Rhode Island, and Connecticut are moderate and getting worse. Massachusetts is really bad.  There is a data error with VA that is making the last couple years look bad, but the data people at GARFO have tracked that down to: 

The issue is related to the underlying data and processing of state Warehouse records at ACCSP.  Some state partners upload state landings to the ACCSP Warehouse on an annual basis.  ACCSP performs a matching routine on those uploads that cross references them to Federal dealer landings in SAFIS.  If the match is successful, those Warehouse records are not ingested into SAFIS and therefore not ingested into CFDERS.

There is also something funky with DE: about 50% of the landings in 2022 and 2023 are not matching to permits, which is surprising because 94% of the quota is subject to a vtr requirement.

```{r CAMS_match_Fraction, fig.show = "hold", out.width = "75%", fig.cap="Fraction of Landings with Matched VTR information",  fig.align = "center", echo=FALSE}
knitr::include_graphics(file.path(exploratory_images,c("cams_match_state.png")))
```

For the entire region, it looks like have matches for about 2/3rds of the black sea bass landings. 
```{r cams_state_veslog, fig.show = "hold", out.width = "48%", fig.cap="Fraction of Landings with Matched VTR information",  fig.align = "center", echo=FALSE}
knitr::include_graphics(file.path(exploratory_images,c("cams_veslog_hails.png","state_cams_veslog_hails.png")))
```


## Gears

The fishery is mostly Trawl and Trap, there is a little bit of Hand and gillnet. Trap seems to be growing in importance.

```{r gears_by_Category_select_years, fig.show = "hold", out.width = "48%", fig.cap="Nominal Prices by Market Category, select years",  fig.align = "center", echo=FALSE}
knitr::include_graphics(file.path(exploratory_images,c("gears_by_year.png", "fgears_by_year.png")))
```


## Prices

If I *need* a model of prices in order to get my main model to work, I can do that. But I don't want to have to do it. 

Prices basically make sense and increase with size. There are definitely tendencies to have prices that in $0.05 and $0.25 increments, which causes the histograms to look really jagged.

```{r Prices_by_Category, fig.show = "hold", out.width = "80%", fig.cap="Nominal Prices by Market Category",  fig.align = "center", echo=FALSE}
knitr::include_graphics(file.path(exploratory_images,c("price_histograms.png")))
```

The premia seem to be roughly constant over time.

```{r Prices_by_Category_select_years, fig.show = "hold", out.width = "48%", fig.cap="Nominal Prices by Market Category, select years",  fig.align = "center", echo=FALSE}
knitr::include_graphics(file.path(exploratory_images,c("price_box1996.png", "price_box2000.png","price_box2008.png", "price_box2016.png")))
```

```{r state_prices_over_time, fig.show = "hold", out.width = "48%", fig.cap="Prices by Market Category, by state",  fig.align = "center", echo=FALSE}
states<-list.files(exploratory_images, pattern=glob2rx("price_overtime_*.png"))
knitr::include_graphics(file.path(exploratory_images,states))
```

## Sizes over time

Over time, there has been more "Large" and "Jumbo." 
```{r Sizes_over_time, fig.show = "hold", out.width = "48%", fig.cap="Market Category over time, All States",  fig.align = "center", echo=FALSE}
knitr::include_graphics(file.path(exploratory_images,c("market_cats_over_time.png", "fmarket_cats_over_time.png")))

```
CT in 2007, although about 20% is still unclassified.

DE in 2001, although the unclassifieds come back in 2022 and 2023.

MA is always classified, although 15 to 20% are unclassified. 

MD is always classified, although there are a few years when it's picks up to 20+%
	MD might also be responsible for the extra smalls in our data in 2018

NC is always classified. And lots of Jumbo.	

NJ is always classified, with about 5-10% per year Unclassified. Jumbo and Large have been increasing there too


NY has quite alot of unclassified Typically 30%

RI starts classifying in 1997, typically less than 5% unclassified.

VA is all classified, except for 2021 to 2023.

One trip pulled in substantially all the Extra small in MD ever in 2019. This feels a little sketch
browse if market_code=="ES" & state=="MD"

```{r Sizes_VA, fig.show = "hold", out.width = "48%", fig.cap="Market Category over time",  fig.align = "center", echo=FALSE}
knitr::include_graphics(file.path(exploratory_images,c("market_cats_VA.png", "fmarket_cats_VA.png")))
```

```{r Sizes_MD, fig.show = "hold", out.width = "48%", fig.cap="Market Category over time",  fig.align = "center", echo=FALSE}
knitr::include_graphics(file.path(exploratory_images,c("market_cats_MD.png", "fmarket_cats_MD.png")))
```


```{r Sizes_DE, fig.show = "hold", out.width = "48%", fig.cap="Market Category over time",  fig.align = "center", echo=FALSE}
knitr::include_graphics(file.path(exploratory_images,c("market_cats_DE.png", "fmarket_cats_DE.png")))
```


```{r Sizes_NJ, fig.show = "hold", out.width = "48%", fig.cap="Market Category over time",  fig.align = "center", echo=FALSE}
knitr::include_graphics(file.path(exploratory_images,c("market_cats_NJ.png", "fmarket_cats_NJ.png")))
```

```{r Sizes_NY, fig.show = "hold", out.width = "48%", fig.cap="Market Category over time",  fig.align = "center", echo=FALSE}
knitr::include_graphics(file.path(exploratory_images,c("market_cats_NY.png", "fmarket_cats_NY.png")))
```


```{r Sizes_CT, fig.show = "hold", out.width = "48%", fig.cap="Market Category over time",  fig.align = "center", echo=FALSE}
knitr::include_graphics(file.path(exploratory_images,c("market_cats_CT.png", "fmarket_cats_CT.png")))
```

```{r Sizes_RI, fig.show = "hold", out.width = "48%", fig.cap="Market Category over time",  fig.align = "center", echo=FALSE}
knitr::include_graphics(file.path(exploratory_images,c("market_cats_RI.png", "fmarket_cats_RI.png")))
```
```{r Sizes_MA, fig.show = "hold", out.width = "48%", fig.cap="Market Category over time",  fig.align = "center", echo=FALSE}
knitr::include_graphics(file.path(exploratory_images,c("market_cats_MA.png", "fmarket_cats_MA.png")))
```

# Vessels over time
How many vessels do I have over time, in each state?  Stacked bar charts of landings in each state. I've dropped out the "unknown" permits and hullids. I ranked each vessel in each state by landings over the 1996-2024 time period. There's no tracking of ownership.  I think the colors within each panel are good (I don't think there is recycling). Colors don't carry over across panels.  Not all states have 25 permits/vessels (DE, MD) 


```{r Permits_VA, fig.show = "hold", out.width = "48%", fig.cap="Landings by Permit in VA",  fig.align = "center", echo=FALSE}
knitr::include_graphics(file.path(exploratory_images,c("permit_VA.png", "hullid_VA.png")))
```

```{r Permits_MD, fig.show = "hold", out.width = "48%", fig.cap="Landings by Permit (L) and Hullid (R) MD",  fig.align = "center", echo=FALSE}
knitr::include_graphics(file.path(exploratory_images,c("permit_MD.png", "hullid_MD.png")))
```


```{r Permits_DE, fig.show = "hold", out.width = "48%", fig.cap="Landings by Permit (L) and Hullid (R) DE",  fig.align = "center", echo=FALSE}
knitr::include_graphics(file.path(exploratory_images,c("permit_DE.png", "hullid_DE.png")))
```


```{r Permits_NJ, fig.show = "hold", out.width = "48%", fig.cap="Landings by Permit (L) and Hullid (R) NJ",  fig.align = "center", echo=FALSE}
knitr::include_graphics(file.path(exploratory_images,c("permit_NJ.png", "hullid_NJ.png")))
```

```{r Permits_NY, fig.show = "hold", out.width = "48%", fig.cap="Landings by Permit (L) and Hullid (R) NY",  fig.align = "center", echo=FALSE}
knitr::include_graphics(file.path(exploratory_images,c("permit_NY.png", "hullid_NY.png")))
```


```{r Permits_CT, fig.show = "hold", out.width = "48%", fig.cap="Landings by Permit (L) and Hullid (R) CT",  fig.align = "center", echo=FALSE}
knitr::include_graphics(file.path(exploratory_images,c("permit_CT.png", "hullid_CT.png")))
```

```{r Permits_RI, fig.show = "hold", out.width = "48%", fig.cap="Landings by Permit (L) and Hullid (R) RI",  fig.align = "center", echo=FALSE}
knitr::include_graphics(file.path(exploratory_images,c("permit_RI.png", "hullid_RI.png")))
```
```{r Permits_MA, fig.show = "hold", out.width = "48%", fig.cap="Landings by Permit (L) and Hullid (R) MA",  fig.align = "center", echo=FALSE}
knitr::include_graphics(file.path(exploratory_images,c("permit_MA.png", "hullid_MA.png")))
```

```{r Permits_overall, fig.show = "hold", out.width = "48%", fig.cap="Landings by Permit (L) and Hullid (R) MA",  fig.align = "center", echo=FALSE}
knitr::include_graphics(file.path(exploratory_images,c("permit_coastwide.png", "hullid_coastwide.png")))
```

# Locations


```{r function_def, eval=FALSE}
  kde2d.weighted <- function (x, y, w, h, n = 25, lims = c(range(x), range(y))) {
  nx <- length(x)
  if (length(y) != nx) 
    stop("data vectors must be the same length")
  if (length(w) != nx & length(w) != 1)
    stop("weight vectors must be 1 or length of data")
  gx <- seq(lims[1], lims[2], length = n) # gridpoints x
  gy <- seq(lims[3], lims[4], length = n) # gridpoints y
  if (missing(h)) 
    h <- c(bandwidth.nrd(x), bandwidth.nrd(y));
  if (missing(w)) 
    w <- numeric(nx)+1;
  h <- h/4
  ax <- outer(gx, x, "-")/h[1] # distance of each point to each grid point in x-direction
  ay <- outer(gy, y, "-")/h[2] # distance of each point to each grid point in y-direction
  z <- (matrix(rep(w,n), nrow=n, ncol=nx, byrow=TRUE)*matrix(dnorm(ax), n, nx)) %*% t(matrix(dnorm(ay), n, nx))/(sum(w) * h[1] * h[2]) # z is the density
  return(list(x = gx, y = gy, z = z))
}

```

# Weighted Fishery location

Here are the annual centers of fishing for the landings that have a valid location. Refer back to the "match" figures

```{r plot_weighted_mean}
working_landings3<-working_landings %>%
  dplyr::filter(!is.na(lon_dd)) %>%
  dplyr::filter(!is.na(lat_dd)) %>%
  mutate(wlon=lndlb*lon_dd,
         wlat=lndlb*lat_dd) %>%
  group_by(state, year)%>%
  summarise(tl=sum(lndlb, na.rm=TRUE),
            lon=sum(wlon)/tl,
            lat=sum(wlat)/tl) %>%
    mutate(time_period=case_when(
  year >=2004 & year<=2009 ~ "2004-2009",
  year >=2010  & year<=2019 ~ "2010-2019",
  year >=2020 ~ "2020+",
  .default = "pre")
  ) %>%
arrange(state,year)

ggplot(working_landings3 %>%dplyr::filter(year>=2000)  %>%dplyr::arrange(state,year) 
       , aes(y=lat, x=lon, label=year, color=time_period)) +
geom_path()  +
 geom_text(size=2)+
    facet_wrap(~state)+  
  #theme(legend.position = "none")+
  scale_fill_viridis(discrete=TRUE)



    




```

```{r contour_plotting,eval=FALSE}

working_landings4<-working_landings %>%
  dplyr::filter(!is.na(lon_dd)) %>%
  dplyr::filter(!is.na(lat_dd)) %>%
  dplyr::select(c(state, year, lat_dd, lon_dd, lndlb)) %>%
  group_split(state,year)


dfdens<-list()


for(i in 1:length(working_landings4)){
  
  input<-working_landings4[[i]]

# You need to do this for each state and for some years. this is probably some sort of split and lapply, right? 
  dens <- kde2d.weighted(input$lon_dd, input$lat_dd, input$lndlb, n=50)
  dfdens[[i]] <- data.frame(expand.grid(x=dens$x, y=dens$y), z=as.vector(dens$z))
  dfdens[[i]]$state<-input$state[1]
  dfdens[[i]]$year<-input$year[1]

}

dfdens<-bind_rows(dfdens) 

dfdens2<-dfdens %>%
  dplyr::filter(state=="DE")

for(i in 1998:2024) {
  i
working<-dfdens2 %>%
  dplyr::filter(year==2000)

ggplot(working) +
    #geom_point() +
    geom_contour(aes(x=x, y=y, z=z))
}

```





# Biological 

```{r, child=here("writing", c("PopulationDynamics.Rmd")),  eval=TRUE}
```


<!---
\newpage
--->
# References
<div id="refs"></div>




