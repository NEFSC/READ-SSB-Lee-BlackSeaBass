---
title: "Black Sea Bass: A Random Forest"
author: "Min-Yang Lee"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  html_document:
    df_print: paged
    fig_caption: yes
  pdf_document:
    keep_tex: yes
    fig_caption: yes
    number_sections: yes
header-includes: \usepackage{setspace}\doublespacing
urlcolor: blue
editor_options:
  chunk_output_type: console
fontsize: 12pt
---

# Summary and Housekeeping


<!---- 
 The global_options chunk loads libraries, sets options, figures out if you're on a desktop or server, sets years, and sets graphing options
 
 If you want to run this from the command line
 
 Rscript -e 'library(rmarkdown); rmarkdown::render("./writing/estimate_randomforest.Rmd", "html_document")' 
 
 This doesn't compile to pdf on the containers (pdflatex not found)
 --->
```{r global_options, include=FALSE}


library("here")

# load tidyverse and related
library("tidyverse")
library("scales")

# load tidyverse and related
library("tidymodels")


# load machine learning and estimation tools
# ranger imports RcppEigen and Rcpp, all 3 need to be compiled on unix.
# you might want to install Rcpp, then RcppEigen, then ranger


library("nnet")
library("ranger")

library("partykit")
library("bonsai")
# load utilities
library("knitr")
library("kableExtra")
library("viridis")
library("conflicted")

#deal with conflicts
conflicts_prefer(dplyr::filter())
conflicts_prefer(dplyr::lag())
conflicts_prefer(purrr::discard())
conflicts_prefer(dplyr::group_rows())
conflicts_prefer(yardstick::spec())
conflicts_prefer(recipes::fixed())
conflicts_prefer(recipes::step())
conflicts_prefer(viridis::viridis_pal())

here::i_am("writing/estimate_randomforest.Rmd")


# Determine what platform the code is running on and set the number of threads for ranger
platform <- Sys.info()['sysname']
# check the name of the effective_user
if(platform == 'Linux'){
  if(Sys.info()['effective_user'] %in% c("mlee")){
      runClass<-'Container'
    }
    else{
      runClass <- 'Local'
    }
  }

if(platform == 'windows'){
  runClass<-'Windows'
}

if (runClass %in% c('Local', 'Windows')){
  my.ranger.threads<-6
} else if (runClass %in% c('Container')){ 
  my.ranger.threads<-12

  }












#############################################################################
#knitr options

knitr::opts_chunk$set(echo=FALSE, warning = FALSE, error = FALSE, message = FALSE, comment = FALSE, cache = FALSE, progress = TRUE, verbose = FALSE, 
											dpi = 600)
options(tinytex.verbose = TRUE)
# options(knitr.table.format = "latex")
options(scipen=999)

lbs_per_mt<-2204.62
#############################################################################
my_images<-here("images")
descriptive_images<-here("images","descriptive")
exploratory_images<-here("images","exploratory")
vintage_string<-list.files(here("data_folder","main","commercial"), pattern=glob2rx("BSB_estimation_dataset*Rds"))
vintage_string<-gsub("BSB_estimation_dataset","",vintage_string)
vintage_string<-gsub(".Rds","",vintage_string)
vintage_string<-max(vintage_string)
estimation_vintage<-as.character(Sys.Date())
```


Most of my data cleaning code is in stata. There's no reason to port it to R and risk mistakes now.  In brief, I:

1. Extract transaction level commercial landings of black sea bass at the camisd+subtrip level (cams_land.rec=0). Any column in CAMS_LAND is available, but sales transactions are tied to a "trip", not a "subtrip". This means there is some uncomfortableness for any transactions corresponding to multi-area (and multi-gear) trips. 
2. I do some "joins" to keyfiles (market category, market grade, gear, and economic deflators).
3. I do some tidying-up (converting datetime variables to date variables)
4. I rebin status=DLR_ORPHAN_SPECIES into status=MATCH

5. There is a little data dropping
  1. landed pounds=0
  2. Some landings from VA and DE that look like aggregates. 
6. I do some binning of gears, loosely into
  1. Line or Hand gear
  2. Trawls
  3. Gillnets
  4. Pot and Trap
  5. Misc=Dredge, Seine, and Unknown.
  
7.  I do some binning of market categories
  1. Unclassified and "Mixed or Unsized" are combined
  2. Small, Extra Small, and Pee Wee (Rats) are combined
  3. Medium and "Medium or Select" are combined.
8.  Ungraded is combined with Round
9. I construct a stockunit indicator
  1. south is 621 and greater, plus 614 and 615 
  2. North is 613 and smaller, plus 616
10. I create a semester indicator (=1 if Jan to June and =2 if July to Dec)
11. I scale landed pounds, nominal value, and deflated value to "thousands". Prices
are in both real and nominal dollars per landed pound. 

```{r load_in_data, include=FALSE}
# this was created with data_prep_ml.Rmd
estimation_dataset<-readr::read_rds(file=here("data_folder","main","commercial",paste0("BSB_estimation_dataset",vintage_string,".Rds")))

#multi4<-multinom(market_desc ~ price + year + state + semester + stockarea, weights=weighting, data=estimation_dataset, abstol=1e-8, reltol=1e-8)

```



```{r simple_ml, include=FALSE}

###################################################
# Inspired by R code for "Big Data: New Tricks for Econometrics
# Journal of Economic Perspectives 28(2), 3-28            
# http://pubs.aeaweb.org/doi/pdfplus/10.1257/jep.28.2.3
# Hal R. Varian

# recoded into a tidymodels setup with recipes and workflows

###################################################


 # for reproducibility
 set.seed(45687)

 # remove obs with missing data, and select a few predictors
 estimation_dataset<-estimation_dataset %>%
   dplyr::filter(is.na(price)==0) %>%
   mutate(dlrid=forcats::as_factor(dlrid)) %>%
 #  dplyr::select(c(market_desc,price,year,state, weighting, stockarea, semester)) %>%
    mutate(market_desc=forcats::fct_relevel(market_desc,c("Jumbo","Large","Medium","Small"))
    )

 # Just for now, just look at post 2018 and take a sample of the data  
  estimation_dataset$rand<-runif(nrow(estimation_dataset))


  estimation_dataset<-estimation_dataset %>%
      dplyr::filter(rand<=0.50)
 

 # construct the "case weights" variable here.
 estimation_dataset<-estimation_dataset %>%
     mutate(weighting = frequency_weights(weighting))

set.seed(4847482)

data_split <- initial_split(data=estimation_dataset, prop=0.8) 
train_data <- training(data_split)
test_data <- testing(data_split)

nrow(train_data)
nrow(test_data)

```




```{r, recipe}

# Use a recipe on the training data. 

#############################
# Handle factor variables 
#############################

# assign roles to predictors, outcome, groups, and weights
BSB.Classification.Recipe <- recipe(train_data) %>%
  update_role(market_desc, new_role = "outcome")%>%
  update_role(dlrid, new_role = "ID variable") %>%
  update_role(c(mygear,price,stockarea, state, year, month, semester, lndlb, grade_desc, dlrid), new_role = "predictor")
  


# You can't center the factor variables
# rescale and recenter 
BSB.Classification.Recipe <- BSB.Classification.Recipe %>% 
#  step_impute_knn(all_predictors()) %>%
  step_center(all_numeric_predictors()) %>%
  step_scale(all_numeric_predictors())
```




```{r define a model}

ranger_model<-rand_forest(mode="classification", trees = 500, min_n=5, mtry=3) %>%
  set_engine("ranger",num.threads=!!my.ranger.threads)


case_weights_allowed(ranger_model)

cf_model<-rand_forest(mode="classification", 
                    trees = 500, min_n=5, mtry=3) %>%
  set_engine("partykit")

case_weights_allowed(cf_model)

```

The workflow is the combination of data processing and model statement

```{r define_workflow}
# Use a workflow that combines the data processing recipe, assigns weights, and the model configuation

BSB.Ranger.Workflow <-
  workflow() %>%
#  add_case_weights(fweight)%>% 
  add_model(ranger_model) %>% 
  add_recipe(BSB.Classification.Recipe)


BSB.cf.Workflow <-
  workflow() %>%
#  add_case_weights(fweight)%>% 
  add_model(cf_model) %>% 
  add_recipe(BSB.Classification.Recipe)

```




```{r fit_model}
set.seed(234)
# Fit the model on the entire training dataset. This of course, is not the best 
# thing to do.  There's 2 parameters that we should search over mtry and min_n
# to find the best model. But this is *a* model.

start_time_1fit<-Sys.time()

rf_fit <- 
  BSB.Ranger.Workflow %>% 
  fit(data = train_data)

end_time_1fit<-Sys.time()

end_time_1fit-start_time_1fit
# Should probably predict out of sample here, but not 

```




We will do 6 fold cross validation over the mtry set of parameters. We'll hold
min_n and trees constant. The number of trees isn't the most important thing.

I'm getting a warning about the precision() and the "small" category, which is probably "macro" metric. Some levels had no predicted
events (i.e. `true_positive + false_positive = 0`). Precision is undefined in this case, and those levels will be removed from the averaged result.

1.  The model is not doing a great job at fitting the "small" class.  The prices of 
small are lower than the prices of medium, but not that much lower.
2.  It might be that we're getting some + probability for smalls, just not enough to be over the threshold. 
3.  There's very little "small" being landed anyway.



```{r hyper_parameter_tuning}


set.seed(95895)
# split the training data group wise into 6 folds
myfolds<-rsample::group_vfold_cv(train_data, group=dlrid, v = 6, balance="observations")

# Set up a set of mtry to search over. This is not a great grid, but it's fine for now
#rf_grid <- grid_regular(
#     mtry(range = c(10, 30)), levels=5)
#rf_grid<-rbind(rf_grid,60)
#rf_grid


mtry<-1:11
rf_grid2<-as.data.frame(mtry)



# configure the tuning part of the model.
tune_spec <- rand_forest(
  mtry = tune(),
  trees = 500,
  min_n = 5,
) %>%
  set_mode("classification") %>%
  set_engine("ranger",num.threads=!!my.ranger.threads)


# make a turning workflow. This combines the Sonar.Recipe "data processing" steps and new "tuning"
# steps as the model.
tune_wf <- workflow() %>%
  add_recipe(BSB.Classification.Recipe) %>%
  add_model(tune_spec)

hardhat::extract_parameter_set_dials(tune_wf)

# pass in a bunch of metrics
class_and_probs_metrics <- metric_set(sensitivity, specificity, precision, bal_accuracy, mn_log_loss,average_precision, accuracy, brier_class, roc_auc)

# Tune the model by passing in the workflow, folds and the rf_grid
# I can look at the canned metrics in  https://yardstick.tidymodels.org/articles/metric-types.html
# I'm more interested in the metrics based on "soft" predictions (class_prob). 
# I will use the class probabilities on the back end, not a 'hard' prediction 
# I'm interested in the 'aggregate predictions', not the 



rf_control_grid<-control_grid(save_pred = TRUE, parallel_over="everything")
start_time_tune<-Sys.time()

tune_res <- tune_grid(
  tune_wf,
  resamples = myfolds,
  grid = rf_grid2,
  control=rf_control_grid,
  metrics=class_and_probs_metrics
)

end_time_tune<-Sys.time()

readr::write_rds(tune_res, file=here("results","ranger",paste0("BSB_ranger_results",estimation_vintage,".Rds")))

end_time_tune-start_time_tune

```


<!---
\newpage
--->
# References
<div id="refs"></div>





# Appendix{-}