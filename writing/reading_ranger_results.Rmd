---
title: "Black Sea Bass: A Random Forest, reading in results"
author: "Min-Yang Lee"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  html_document:
    df_print: paged
    fig_caption: yes
  pdf_document:
    keep_tex: yes
    fig_caption: yes
    number_sections: yes
header-includes: \usepackage{setspace}\doublespacing
urlcolor: blue
editor_options:
  chunk_output_type: console
fontsize: 12pt
---

# Summary and Housekeeping


<!---- 
 The global_options chunk loads libraries, sets options, figures out if you're on a desktop or server, sets years, and sets graphing options
 --->
```{r global_options, include=FALSE}


library("here")

# load tidyverse and related
library("tidyverse")
library("scales")

# load tidyverse and related
library("tidymodels")


# load machine learning and estimation tools
library("nnet")
library("ranger")
library("partykit")
library("bonsai")
library("vip")

# load utilities
library("knitr")
library("kableExtra")
library("viridis")
library("conflicted")

#deal with conflicts
conflicts_prefer(dplyr::filter())
conflicts_prefer(dplyr::lag())
conflicts_prefer(purrr::discard())
conflicts_prefer(dplyr::group_rows())
conflicts_prefer(yardstick::spec())
conflicts_prefer(recipes::fixed())
conflicts_prefer(recipes::step())
conflicts_prefer(viridis::viridis_pal())


here::i_am("writing/reading_ranger_results.Rmd")






#############################################################################
#knitr options

knitr::opts_chunk$set(echo=TRUE, warning = FALSE, error = FALSE, message = FALSE, comment = FALSE, cache = FALSE, progress = TRUE, verbose = FALSE, 
											dpi = 600)
options(tinytex.verbose = TRUE)
# options(knitr.table.format = "latex")
options(scipen=999)

lbs_per_mt<-2204.62
#############################################################################
my_images<-here("images")
descriptive_images<-here("images","descriptive")
exploratory_images<-here("images","exploratory")


data_vintage_string<-list.files(here("results","ranger"), pattern=glob2rx("data_split*Rds"))
data_vintage_string<-gsub("data_split","",data_vintage_string)
data_vintage_string<-gsub(".Rds","",data_vintage_string)
data_vintage_string<-max(data_vintage_string)


tuning_vintage<-list.files(here("results","ranger"), pattern=glob2rx("BSB_ranger_tune*Rds"))
tuning_vintage<-gsub("BSB_ranger_tune","",tuning_vintage)
tuning_vintage<-gsub(".Rds","",tuning_vintage)
tuning_vintage<-max(tuning_vintage)


finalfit_vintage<-list.files(here("results","ranger"), pattern=glob2rx("BSB_ranger_results*Rds"))
finalfit_vintage<-gsub("BSB_ranger_results","",finalfit_vintage)
finalfit_vintage<-gsub(".Rds","",finalfit_vintage)
finalfit_vintage<-max(finalfit_vintage)


```

Data vintage is `r data_vintage_string`. Tuning vintage is `r tuning_vintage`.  Final fit vintage is `r finalfit_vintage`.

```{r load_in_data and tuning_results, include=FALSE}
# this was created with data_prep_ml.Rmd
data_split<-readr::read_rds(file=here("results","ranger",paste0("data_split",data_vintage_string,".Rds")))
tune_res<-readr::read_rds(file=here("results","ranger",paste0("BSB_ranger_tune",tuning_vintage,".Rds")))

```

Brier classification suggests an mtry around 12 to 14.  Number of trees doesn't matter much.

```{r brier_class}

# eyeball the metrics 
all.metrics<-tune_res %>%
  collect_metrics() 

best_tree <- tune_res %>%
  select_best(metric = "mn_log_loss")

brier<-all.metrics %>%
  filter(.metric == "brier_class") %>%
  select(mean, mtry,trees) %>%
  rename(brier_class=mean) %>%
  mutate(trees=as.factor(trees))

 brier %>% ggplot(aes(mtry, brier_class, color=trees)) +
  geom_point(show.legend = TRUE) 

 ggsave(here("results","ranger","tune",paste0("brier_class.png",tuning_vintage,".png")), plot=last_plot())

```

Multinomial log-loss suggests mtry of 9 and that 1000 trees is a little better than 500.

```{r log_loss}
mn_log_loss<-all.metrics %>%
  filter(.metric == "mn_log_loss") %>%
#  filter(mtry <=10) %>%
  select(mean, mtry,trees) %>%
  rename(mn_log_loss=mean) %>%
  mutate(trees=as.factor(trees))

 mn_log_loss %>% ggplot(aes(mtry, mn_log_loss, color=trees)) +
  geom_point(show.legend = TRUE) 

 ggsave(here("results","ranger","tune",paste0("mn_log_loss.png",tuning_vintage,".png")), plot=last_plot())

```


Are there any warnings from the tuning?

```{r warnings}
extracts<-tune_res %>%
  collect_notes()
extracts
not_good<-unique(extracts$id)
not_good
```
There are warnings in all the runs, all related to computation of precision.  All but 1 are due to "no predicted" smalls; one is due to no-predicted medium.


# Some in-sample results from Tuning

```{r roc}
# A ROC curve. I'm not sure if this is quite right, but I think it is.
predictions<-tune_res %>%
  collect_predictions()


predictions %>%
  group_by(id, mtry) %>%
  dplyr::filter(mtry==11) %>%
  #dplyr::filter(!id %in% not_good) %>%
  roc_curve(market_desc, .pred_Jumbo:.pred_Small) %>%
  autoplot()



test2<-predictions %>%
  group_by(id, mtry) %>%
  dplyr::filter(mtry==11) %>%
  #dplyr::filter(!id %in% not_good) %>%
  roc_curve(market_desc, .pred_Jumbo:.pred_Small)


ggsave(here("results","ranger","tune",paste0("roc_tune_",tuning_vintage,".png")), plot=last_plot())


predictions %>%
  group_by(id, mtry) %>%
  dplyr::filter(mtry==11)%>%
#  dplyr::filter(!id %in% not_good) %>%
  pr_curve(market_desc, .pred_Jumbo:.pred_Small) %>%
  autoplot()

ggsave(here("results","ranger","tune",paste0("pr_curve_tune_",tuning_vintage,".png")), plot=last_plot())


  
```

```{r load_final_model}

rm(tune_res)

final_fit<-readr::read_rds(file=here("results","ranger",paste0("BSB_ranger_results",tuning_vintage,".Rds")))

# What is the workflow
final_fit$.workflow

# And the recipe
final_fit$.workflow[[1]]$pre$actions$recipe$recipe

preds<-final_fit$.workflow[[1]]$pre$actions$recipe$recipe$var_info %>%
 dplyr::filter(role=="predictor")

num_preds<-nrow(preds)

```


```{r final_predictions}
# Get predictions
final_predictions<-final_fit %>%
  collect_predictions()

# look at the fit metrics
final_fit_metrics<-final_fit %>%
  collect_metrics()
final_fit_metrics

# Look at variable importance. I want to see all the predictors
final_fit %>% 
  extract_fit_parsnip() %>% 
  vip(num_features = num_preds)
ggsave(here("results","ranger","final",paste0("vip",finalfit_vintage,".png")), plot=last_plot())

# Reciever operator curve (True positive vs False Positive) for the final model applied to the hold-out sample
final_predictions %>%
  roc_curve(market_desc, .pred_Jumbo:.pred_Small) %>%
  autoplot()
ggsave(here("results","ranger","final",paste0("roc_",finalfit_vintage,".png")), plot=last_plot())

# PR curve
final_predictions %>%
  pr_curve(market_desc, .pred_Jumbo:.pred_Small) %>%
  autoplot()
ggsave(here("results","ranger","final",paste0("pr_curve",finalfit_vintage,".png")), plot=last_plot())
```


```{r predicted_pounds}
# Compute predicted pounds for the validation dataset
#pull the test data, merge it with the predictions
test_data <- testing(data_split)
test_data<-test_data %>%
  rename(market_descOG=market_desc)
test_data<-cbind(test_data, final_predictions)

# keep just a few columns
test_data<-test_data %>%
  select(c(camsid, weighting, market_desc, lndlb, stockarea, year, market_descOG, .pred_Jumbo:.pred_Small, .pred_class))

#predicted pounds per transaction in the validation dataset.
test_data<-test_data %>%
   mutate(predJ=.pred_Jumbo*lndlb,
          predL=.pred_Large*lndlb,
          predM=.pred_Medium*lndlb,
          predS=.pred_Small*lndlb)
 
# This is basically a confusion matrix at the stockarea-year level.
 aggregate_predictions<-test_data %>%
   group_by(stockarea, year,market_desc) %>%
   summarise(predJ=sum(predJ),
          predL=sum(predL),
          predM=sum(predM),
          predS=sum(predS),
          true_pounds=sum(lndlb)
  )
```




<!---
\newpage
--->
# References
<div id="refs"></div>





# Appendix{-}