---
title: "Black Sea Bass: A Random Forest, reading in results"
author: "Min-Yang Lee"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  html_document:
    df_print: paged
    fig_caption: yes
  pdf_document:
    keep_tex: yes
    fig_caption: yes
    number_sections: yes
header-includes: \usepackage{setspace}\doublespacing
urlcolor: blue
editor_options:
  chunk_output_type: console
fontsize: 12pt
---

# Summary and Housekeeping


<!---- 
 The global_options chunk loads libraries, sets options, figures out if you're on a desktop or server, sets years, and sets graphing options
 --->
```{r global_options, include=FALSE}


library("here")

# load tidyverse and related
library("tidyverse")
library("scales")

# load tidyverse and related
library("tidymodels")


# load machine learning and estimation tools
library("nnet")
library("ranger")
library("partykit")
library("bonsai")
# load utilities
library("knitr")
library("kableExtra")
library("viridis")
library("conflicted")

#deal with conflicts
conflicts_prefer(dplyr::filter())
conflicts_prefer(dplyr::lag())
conflicts_prefer(purrr::discard())
conflicts_prefer(dplyr::group_rows())
conflicts_prefer(yardstick::spec())
conflicts_prefer(recipes::fixed())
conflicts_prefer(recipes::step())
conflicts_prefer(viridis::viridis_pal())


here::i_am("writing/reading_ranger_results.Rmd")






#############################################################################
#knitr options

knitr::opts_chunk$set(echo=FALSE, warning = FALSE, error = FALSE, message = FALSE, comment = FALSE, cache = FALSE, progress = TRUE, verbose = FALSE, 
											dpi = 600)
options(tinytex.verbose = TRUE)
# options(knitr.table.format = "latex")
options(scipen=999)

lbs_per_mt<-2204.62
#############################################################################
my_images<-here("images")
descriptive_images<-here("images","descriptive")
exploratory_images<-here("images","exploratory")


data_vintage_string<-list.files(here("data_folder","main","commercial"), pattern=glob2rx("BSB_estimation_dataset*Rds"))
data_vintage_string<-gsub("BSB_estimation_dataset","",data_vintage_string)
data_vintage_string<-gsub(".Rds","",data_vintage_string)
data_vintage_string<-max(data_vintage_string)


tuning_vintage<-list.files(here("results","ranger"), pattern=glob2rx("BSB_ranger_tune*Rds"))
tuning_vintage<-gsub("BSB_ranger_tune","",tuning_vintage)
tuning_vintage<-gsub(".Rds","",tuning_vintage)
tuning_vintage<-max(tuning_vintage)


finalfit_vintage<-list.files(here("results","ranger"), pattern=glob2rx("BSB_ranger_results*Rds"))
finalfit_vintage<-gsub("BSB_ranger_results","",finalfit_vintage)
finalfit_vintage<-gsub(".Rds","",finalfit_vintage)
finalfit_vintage<-max(finalfit_vintage)


```

Data vintage is `r data_vintage_string`. Tuning vintage is `r tuning_vintage`.  Final fit vintage is `r finalfit_vintage`.

```{r load_in_data and results, include=FALSE}
# this was created with data_prep_ml.Rmd
estimation_dataset<-readr::read_rds(file=here("data_folder","main","commercial",paste0("BSB_estimation_dataset",data_vintage_string,".Rds")))
tune_res<-readr::read_rds(file=here("results","ranger",paste0("BSB_ranger_tune",tuning_vintage,".Rds")))

#final_fit<-readr::read_rds(file=here("results","ranger",paste0("BSB_ranger_results",tuning_vintage,".Rds")))



```

Brier classification suggests an mtry around 5 to 7.

```{r hyper_parameter_tuning_results}

# eyeball the metrics 
all.metrics<-tune_res %>%
  collect_metrics() 

all.metrics %>%
  filter(.metric == "brier_class") %>%
  filter(mtry <=15) %>%

  select(mean, mtry) %>%
  pivot_longer(mtry,
    values_to = "value",
    names_to = "parameter"
  ) %>%
  ggplot(aes(value, mean, color = parameter)) +
  geom_point(show.legend = FALSE) +
  facet_wrap(~parameter, scales = "free_x") +
  labs(x = NULL, y = "brier_class")
#ggsave(here("writing","presentations","2025_03_24_Economic_Informed_Stock_Assessments","brier_class.png"), plot=last_plot())

```

Brier classification suggests mtry around 5 or 6.

```{r hyper_parameter_tuning_results}
all.metrics %>%
  filter(.metric == "mn_log_loss") %>%
  filter(mtry <=10) %>%
  select(mean, mtry) %>%
  pivot_longer(mtry,
    values_to = "value",
    names_to = "parameter"
  ) %>%
  ggplot(aes(value, mean, color = parameter)) +
  geom_point(show.legend = FALSE) +
  facet_wrap(~parameter, scales = "free_x") +
  labs(x = NULL, y = "mn_log_loss")


#ggsave(here("writing","presentations","2025_03_24_Economic_Informed_Stock_Assessments","mn_log_loss.png"), plot=last_plot())
```


Are there any warnings from the tuning?

```{r roc}
extracts<-tune_res %>%
  collect_notes()
extracts
not_good<-unique(extracts$id)
notgood
```
Yes, a few resamples have some odd results. In Resamples 2 and 4, Small is never predicted, but there are some small that actually occur.  When this happens, Precision is undefined.

In other resamples, there is difficulty computing Sensitivity or Recall because there are no "true" events (like no smalls).

```{r warnings}
# A ROC curve. I'm not sure if this is quite right, but I think it is.
predictions<-tune_res %>%
  collect_predictions()


predictions %>%
  group_by(id, mtry) %>%
  dplyr::filter(mtry==5) %>%
  dplyr::filter(!id %in% not_good) %>%

  roc_curve(market_desc, .pred_Jumbo:.pred_Small) %>%
  autoplot()
ggsave(here("writing","presentations","2025_03_24_Economic_Informed_Stock_Assessments","roc_tune.png"), plot=last_plot())


predictions %>%
  group_by(id, mtry) %>%
  dplyr::filter(mtry==5)%>%
  dplyr::filter(!id %in% not_good) %>%
  pr_curve(market_desc, .pred_Jumbo:.pred_Small) %>%
  autoplot()
ggsave(here("writing","presentations","2025_03_24_Economic_Informed_Stock_Assessments","pr_curve_tune.png"), plot=last_plot())


  
```

```{r }

predictions<-final_fit %>%
  collect_predictions()

# I have "true", I just need to merge in "weighting"  


predictions<-predictions %>%
  mutate(predJ=.pred_Jumbo*weighting,
         predL=.pred_Large*weighting,
         predM=.pred_Medium*weighting,
         predS=.pred_Small*weighting)


aggregate_predictions<-predictions %>%
  group_by(market_desc) %>%
  summarise(predJ=sum(predJ),
         predL=sum(predJ),
         predM=sum(predJ),
         predS=sum(predJ),
         true_pounds=sum(weighting)
  )



```




<!---
\newpage
--->
# References
<div id="refs"></div>





# Appendix{-}